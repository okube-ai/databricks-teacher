name: pl-databricks-exams

orchestrator: DATABRICKS_JOB
databricks_job:
  name: job-pl-databricks-exams
  clusters:
    - name: node-cluster
      autoscale:
        min_workers: 1
        max_workers: 2
      spark_version: 15.3.x-scala2.12
      node_type_id: Standard_DS3_v2

udfs:
  - module_name: custom_functions
    function_name: binary_to_text
  - module_name: custom_functions
    function_name: summarize_guide
  - module_name: custom_functions
    function_name: get_section_content
  - module_name: custom_functions
    function_name: join_questions
#  - module_name: custom_functions
#    function_name: get_question_section
#  - module_name: custom_functions
#    function_name: get_question_section_index

# --------------------------------------------------------------------------- #
# Nodes                                                                       #
# --------------------------------------------------------------------------- #

nodes:

  # ------------------------------------------------------------------------- #
  # Exam Udemy Questions                                                      #
  # ------------------------------------------------------------------------- #

  - name: brz_udemy_exam_questions
    layer: BRONZE
    source:
      path: /Volumes/${vars.env}/sources/landing/events/udemy/databricks-exams/
      as_stream: true
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: brz_udemy_exam_questions
      mode: APPEND
      checkpoint_location: /Volumes/${vars.env}/sources/landing/laktory/pipelines/pl-databricks-exams/brz_udemy_exam_questions/checkpoint/

  - name: slv_udemy_exam_questions
    source:
      node_name: brz_udemy_exam_questions
      as_stream: true
#      filter: exam_type != 'analyst-associate' OR  CAST(exam_index AS int) > 4
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: slv_udemy_exam_questions
      mode: APPEND
      checkpoint_location: /Volumes/${vars.env}/sources/landing/laktory/pipelines/pl-databricks-exams/slv_udemy_exam_questions/checkpoint/
    drop_duplicates:
      - question
    transformer:
      nodes:
        - with_columns:
          - name: exam_type
            sql_expr: exam_type
          - name: exam_index
            type: int
            sql_expr: exam_index
          - name: question_index
            type: int
            sql_expr: question_index
          - name: section_index
            type: int
            sql_expr: section_index
          - name: section_id
            expr: F.concat_ws("-", "exam_type", "section_index")
          - name: question
            sql_expr: question
          - name: A
            sql_expr: A
          - name: B
            sql_expr: B
          - name: C
            sql_expr: C
          - name: D
            sql_expr: D
          - name: E
            sql_expr: E
          - name: question_and_answers
            expr: F.concat_ws("\n", "question", F.concat(F.lit("A) "), "A"), F.concat(F.lit("B) "), "B"), F.concat(F.lit("C) "), "C"), F.concat(F.lit("D) "), "D"), F.concat(F.lit("E) "), "E"))

  # ------------------------------------------------------------------------- #
  # Exam Guides                                                               #
  # ------------------------------------------------------------------------- #

  - name: brz_exam_guides
    layer: BRONZE
    source:
      path: /Volumes/${vars.env}/sources/landing/events/databricks/exam-guides/
      format: BINARYFILE
      as_stream: true
      read_options:
        cloudFiles.schemaEvolutionMode: none
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: brz_exam_guides
      mode: APPEND
      checkpoint_location: /Volumes/${vars.env}/sources/landing/laktory/pipelines/pl-databricks-exams/brz_exam_guides/checkpoint/
    transformer:
      nodes:
        - with_column:
            name: _file
            sql_expr: _metadata.file_path

  - name: slv_exam_guides
    source:
      node_name: brz_exam_guides
      as_stream: true
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: slv_exam_guides
      mode: APPEND
      checkpoint_location: /Volumes/${vars.env}/sources/landing/laktory/pipelines/pl-databricks-exams/slv_exam_guides/checkpoint/
    transformer:
      nodes:
      - with_columns:
        - name: content
          type: null
          expr: binary_to_text("content")
#        - name: id
#          expr: row_id("path", "content")
#        - name: embedding
#          type: null
#          expr: embed("content")
        - name: exam_type
          type: null
          sql_expr: regexp_extract(_file, '/([^/.]+).pdf$', 1)
        - name: summary
          expr: summarize_guide("content")
      - func_name: drop
        func_args:
          - _file
          - modificationTime


  # ------------------------------------------------------------------------- #
  # Exam Sections                                                             #
  # ------------------------------------------------------------------------- #

  - name: brz_exam_sections
    layer: BRONZE
    source:
      path: /Volumes/${vars.env}/sources/landing/events/databricks/exam-sections/
      format: JSON
      as_stream: False
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: brz_exam_sections
      mode: OVERWRITE

  - name: slv_exam_sections
    source:
      node_name: brz_exam_sections
      as_stream: false
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: slv_exam_sections
      mode: OVERWRITE
    transformer:
      nodes:
      - with_columns:
        - name: exam_type
          type: null
          sql_expr: exam_type
        - name: index
          type: int
          sql_expr: index
        - name: name
          sql_expr: name
        - name: weight
          type: double
          sql_expr: weight
        - name: id
          expr: F.concat_ws("-", "exam_type", "index")
      - func_name: laktory.smart_join
        func_kwargs:
          other:
            node_name: slv_exam_guides
            selects:
              exam_type: exam_type
              content: exam_content
          "on":
            - exam_type

      - with_columns:
        - name: content
          expr: get_section_content("exam_content", "name")

      - func_name: join_questions
        func_kwargs:
          other:
            node_name: slv_udemy_exam_questions

      - func_name: drop
        func_args:
          - section
          - exam_content

  # ------------------------------------------------------------------------- #
  # Exam Questions                                                            #
  # ------------------------------------------------------------------------- #

  - name: brz_exam_questions
    source:
      path: /Volumes/${vars.env}/sources/landing/events/okube/databricks_exam_question/
      format: JSON
      as_stream: False
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: brz_exam_questions
      mode: OVERWRITE

  - name: slv_exam_questions
    layer: SILVER
    source:
      node_name: brz_exam_questions
      as_stream: False
    sink:
      catalog_name: ${vars.env}
      schema_name: databricks
      table_name: slv_exam_questions
      mode: OVERWRITE
    transformer:
      nodes:
      - with_columns:
        - name: uuid
          sql_expr: data.uuid
        - name: run_id
          sql_expr: data.run_id
        - name: created_at
          type: timestamp
          sql_expr: data.created_at
        - name: exam_type
          sql_expr: data.exam_type
        - name: section_index
          type: int
          sql_expr: data.section_index
        - name: section_name
          sql_expr: data.section_name
        - name: section_id
          sql_expr: data.section_id
        - name: question
          sql_expr: data.question
        - name: A
          sql_expr: data.A
        - name: B
          sql_expr: data.B
        - name: C
          sql_expr: data.C
        - name: D
          sql_expr: data.D
        - name: E
          sql_expr: data.E
        - name: answer
          sql_expr: data.answer
        - name: explanation
          sql_expr: data.explanation


#
#  # ------------------------------------------------------------------------- #
#  # Documentation                                                             #
#  # ------------------------------------------------------------------------- #
#
#  - name: brz_documentation
#    layer: BRONZE
#    source:
#      path: /Volumes/${vars.env}/sources/landing/events/databricks/documentation/
#      format: BINARYFILE
#      as_stream: true
#      read_options:
#        cloudFiles.schemaEvolutionMode: none
#    sink:
#      catalog_name: ${vars.env}
#      schema_name: databricks
#      table_name: brz_documentation
#      mode: APPEND
#      checkpoint_location: /Volumes/${vars.env}/sources/landing/laktory/pipelines/pl-databricks-exams/brz_documentation
#    transformer:
#      nodes:
#      - with_columns:
#        - name: _file
#          sql_expr: _metadata.file_path
#
#
#  - name: slv_documentation
##    layer: SILVER
#    source:
#      node_name: brz_documentation
#      as_stream: true
#    sink:
#      catalog_name: ${vars.env}
#      schema_name: databricks
#      table_name: slv_documentation
#      mode: APPEND
#      checkpoint_location: /Volumes/${vars.env}/sources/landing/laktory/pipelines/pl-databricks-exams/slv_documentation
#      - func_name: drop
#        func_args:
#          - _file
#          - modificationTime
#          - length